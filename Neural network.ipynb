{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # to eliminate tensorflow warnings about NUMA nodes\nimport cv2\nimport glob\nimport PIL\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom skimage import data\nfrom skimage.util import montage \nimport skimage.transform as skTrans\nfrom skimage.transform import rotate\nfrom skimage.transform import resize\nfrom PIL import Image, ImageOps  \nimport sys; print(sys.version)\nimport datasets\n\n# neural imaging\nimport nilearn as nl\nimport nibabel as nib\nimport nilearn.plotting as nlplt\n\n\n# ml libs\nimport keras\nimport keras.backend as K\nfrom keras.callbacks import CSVLogger\nimport tensorflow as tf\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n\n# Make numpy printouts easier to read.\nnp.set_printoptions(precision=3, suppress=True)","metadata":{"_uuid":"4512b3aa-c669-4bac-bc19-20779507076f","_cell_guid":"b03e3b58-652c-45d8-874b-a4c67d39e26a","collapsed":false,"id":"epSn0XvegANV","execution":{"iopub.status.busy":"2022-10-06T21:19:38.674674Z","iopub.execute_input":"2022-10-06T21:19:38.675687Z","iopub.status.idle":"2022-10-06T21:19:46.753631Z","shell.execute_reply.started":"2022-10-06T21:19:38.675586Z","shell.execute_reply":"2022-10-06T21:19:46.752385Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DEFINE seg-areas  \nSEGMENT_CLASSES = {\n    0 : 'NOT tumor',   \n    1 : 'NECROTIC/CORE', # or NON-ENHANCING tumor CORE - RED\n    2 : 'EDEMA',  # Green\n    3 : 'ENHANCING' # original 4 -> converted into 3 later, Yellow\n}\n\n# there are 155 slices per volume\n# to start at 5 and use 145 slices means we will skip the first 5 and last 5 \nVOLUME_SLICES = 100 \nVOLUME_START_AT = 22 # first slice of volume that we will include\n\nIMG_SIZE=128","metadata":{"_uuid":"4f3cdcc2-28b4-404f-9d17-6eb560976d8f","_cell_guid":"cada9162-f33a-4be4-a76f-9db73e82a9f1","collapsed":false,"id":"eLSnyB2xi5rc","execution":{"iopub.status.busy":"2022-10-06T21:19:46.755676Z","iopub.execute_input":"2022-10-06T21:19:46.756350Z","iopub.status.idle":"2022-10-06T21:19:46.771504Z","shell.execute_reply.started":"2022-10-06T21:19:46.756317Z","shell.execute_reply":"2022-10-06T21:19:46.765933Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tarfile\nfile = tarfile.open('../input/brats-2021-task1/BraTS2021_Training_Data.tar')\n\nfile.extractall('./BraTS2021_Training_Data')\nfile.close()","metadata":{"_uuid":"a324b71f-c749-4ace-8225-9fccb8b3f9da","_cell_guid":"7095b6d5-9300-4103-91d3-a8994a088ed5","collapsed":false,"execution":{"iopub.status.busy":"2022-10-06T21:19:46.777272Z","iopub.execute_input":"2022-10-06T21:19:46.777535Z","iopub.status.idle":"2022-10-06T21:21:48.626296Z","shell.execute_reply.started":"2022-10-06T21:19:46.777510Z","shell.execute_reply":"2022-10-06T21:21:48.625287Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file = tarfile.open('../input/brats-2021-task1/BraTS2021_00621.tar')\n\nfile.extractall('./sample_img')\nfile.close()\n\nnSample = os.listdir('./sample_img')\nnSample","metadata":{"_uuid":"27969316-16fd-4ef9-89e1-46570d6bdbe9","_cell_guid":"74b00f9a-3186-4562-a59c-11097a687379","collapsed":false,"execution":{"iopub.status.busy":"2022-10-06T21:21:48.628516Z","iopub.execute_input":"2022-10-06T21:21:48.629227Z","iopub.status.idle":"2022-10-06T21:21:48.741771Z","shell.execute_reply.started":"2022-10-06T21:21:48.629189Z","shell.execute_reply":"2022-10-06T21:21:48.740916Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DATASET_PATH = './BraTS2021_Training_Data/'","metadata":{"_uuid":"3e218403-462d-493d-86e3-0f1043e72083","_cell_guid":"513c187f-78ad-4871-855a-ec5657860b12","collapsed":false,"id":"JxAtml6VjH2y","execution":{"iopub.status.busy":"2022-10-06T21:21:48.743133Z","iopub.execute_input":"2022-10-06T21:21:48.743571Z","iopub.status.idle":"2022-10-06T21:21:48.749127Z","shell.execute_reply.started":"2022-10-06T21:21:48.743536Z","shell.execute_reply":"2022-10-06T21:21:48.748030Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nSample = os.listdir(TRAIN_DATASET_PATH + 'BraTS2021_01261')\nnSample","metadata":{"_uuid":"b6ac3c5b-9624-4045-923c-a3dae268e300","_cell_guid":"26a9b660-3c17-4277-b398-a2be48e22be8","collapsed":false,"execution":{"iopub.status.busy":"2022-10-06T21:21:48.751435Z","iopub.execute_input":"2022-10-06T21:21:48.752576Z","iopub.status.idle":"2022-10-06T21:21:48.762181Z","shell.execute_reply.started":"2022-10-06T21:21:48.752542Z","shell.execute_reply":"2022-10-06T21:21:48.761020Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_flair=nib.load(TRAIN_DATASET_PATH + 'BraTS2021_01261/BraTS2021_01261_flair.nii.gz').get_fdata()\ntest_image_t1=nib.load(TRAIN_DATASET_PATH + 'BraTS2021_01261/BraTS2021_01261_t1.nii.gz').get_fdata()\ntest_image_t1ce=nib.load(TRAIN_DATASET_PATH + 'BraTS2021_01261/BraTS2021_01261_t1ce.nii.gz').get_fdata()\ntest_image_t2=nib.load(TRAIN_DATASET_PATH + 'BraTS2021_01261/BraTS2021_01261_t2.nii.gz').get_fdata()\ntest_mask=nib.load(TRAIN_DATASET_PATH + 'BraTS2021_01261/BraTS2021_01261_seg.nii.gz').get_fdata()","metadata":{"_uuid":"d0209efa-b9a1-4c5b-a149-27bc8bd21c7c","_cell_guid":"b321b5cf-4d4e-4490-b308-efa5b8474c7d","collapsed":false,"id":"EpWEBjNFjk5j","execution":{"iopub.status.busy":"2022-10-06T21:21:48.765776Z","iopub.execute_input":"2022-10-06T21:21:48.766042Z","iopub.status.idle":"2022-10-06T21:21:49.523392Z","shell.execute_reply.started":"2022-10-06T21:21:48.766019Z","shell.execute_reply":"2022-10-06T21:21:49.522350Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5, figsize = (20, 10))\nslice_w = 25\nax1.imshow(test_image_flair[:,:,test_image_flair.shape[0]//2-slice_w], cmap = 'gray')\nax1.set_title('Image flair')\nax2.imshow(test_image_t1[:,:,test_image_t1.shape[0]//2-slice_w], cmap = 'gray')\nax2.set_title('Image t1')\nax3.imshow(test_image_t1ce[:,:,test_image_t1ce.shape[0]//2-slice_w], cmap = 'gray')\nax3.set_title('Image t1ce')\nax4.imshow(test_image_t2[:,:,test_image_t2.shape[0]//2-slice_w], cmap = 'gray')\nax4.set_title('Image t2')\nax5.imshow(test_mask[:,:,test_mask.shape[0]//2-slice_w])\nax5.set_title('Mask')","metadata":{"_uuid":"72000f2a-0454-4459-acb6-0ce94614f4cc","_cell_guid":"b9dc662b-01d6-413d-8cf7-763d2d73eff8","collapsed":false,"id":"FbSEFiSlk-qW","outputId":"c653f9ae-70fc-432b-9e3f-d25abafa90f0","execution":{"iopub.status.busy":"2022-10-06T21:21:49.526556Z","iopub.execute_input":"2022-10-06T21:21:49.526961Z","iopub.status.idle":"2022-10-06T21:21:50.149817Z","shell.execute_reply.started":"2022-10-06T21:21:49.526924Z","shell.execute_reply":"2022-10-06T21:21:50.148874Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\nax1.imshow(rotate(montage(test_image_t1[50:-50,:,:]), 90, resize=True), cmap ='gray')","metadata":{"_uuid":"915d0d1c-d7c1-4f95-a620-7b26797bc383","_cell_guid":"62b47ebb-7699-4dcf-9cc9-5a616f508dce","collapsed":false,"id":"XxL-GB0TlZUz","outputId":"26272267-a154-40a3-d31a-3dce1d30db41","execution":{"iopub.status.busy":"2022-10-06T21:21:50.154266Z","iopub.execute_input":"2022-10-06T21:21:50.154547Z","iopub.status.idle":"2022-10-06T21:21:51.271391Z","shell.execute_reply.started":"2022-10-06T21:21:50.154521Z","shell.execute_reply":"2022-10-06T21:21:51.268950Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax1 = plt.subplots(1, 1, figsize = (15,15))\nax1.imshow(rotate(montage(test_mask[60:-60,:,:]), 90, resize=True), cmap ='gray')","metadata":{"_uuid":"9ce92ed3-662f-4da6-98be-f2bf710b4b4d","_cell_guid":"06b20aa8-f31d-4932-8718-482daed1fc77","collapsed":false,"id":"k5py1Ka3leWj","outputId":"6590c206-18db-4878-d794-49bbbafc4833","execution":{"iopub.status.busy":"2022-10-06T21:21:51.272999Z","iopub.execute_input":"2022-10-06T21:21:51.274077Z","iopub.status.idle":"2022-10-06T21:21:52.217911Z","shell.execute_reply.started":"2022-10-06T21:21:51.274039Z","shell.execute_reply":"2022-10-06T21:21:52.216798Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"niimg = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS2021_01261/BraTS2021_01261_flair.nii.gz')\nnimask = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS2021_01261/BraTS2021_01261_seg.nii.gz')\n\nfig, axes = plt.subplots(nrows=4, figsize=(30, 40))\n\n\nnlplt.plot_anat(niimg,\n                title='BraTS18_Training_001_flair.nii plot_anat',\n                axes=axes[0])\n\nnlplt.plot_epi(niimg,\n               title='BraTS18_Training_001_flair.nii plot_epi',\n               axes=axes[1])\n\nnlplt.plot_img(niimg,\n               title='BraTS18_Training_001_flair.nii plot_img',\n               axes=axes[2])\n\nnlplt.plot_roi(nimask, \n               title='BraTS18_Training_001_flair.nii with mask plot_roi',\n               bg_img=niimg, \n               axes=axes[3], cmap='Paired')\n\nplt.show()","metadata":{"_uuid":"d7303c58-adf9-473f-9904-04cebbea36ba","_cell_guid":"70363f00-eb30-45ec-b2cf-21eb34bf04ab","collapsed":false,"id":"0dg9dpFjlh0L","outputId":"df3fae64-81c9-4488-e64a-bb4b218840f3","execution":{"iopub.status.busy":"2022-10-06T21:21:52.219427Z","iopub.execute_input":"2022-10-06T21:21:52.220412Z","iopub.status.idle":"2022-10-06T21:22:01.930472Z","shell.execute_reply.started":"2022-10-06T21:21:52.220374Z","shell.execute_reply":"2022-10-06T21:22:01.929628Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dice loss as defined above for 4 classes\ndef dice_coef(y_true, y_pred, smooth=1.0):\n    class_num = 4\n    for i in range(class_num):\n        y_true_f = K.flatten(y_true[:,:,:,i])\n        y_pred_f = K.flatten(y_pred[:,:,:,i])\n        intersection = K.sum(y_true_f * y_pred_f)\n        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n   #     K.print_tensor(loss, message='loss value for class {} : '.format(SEGMENT_CLASSES[i]))\n        if i == 0:\n            total_loss = loss\n        else:\n            total_loss = total_loss + loss\n            \n    total_loss = total_loss / class_num\n#    K.print_tensor(total_loss, message=' total dice coef: ')\n    return total_loss\n\n\n \n# define per class evaluation of dice coef\n# inspired by https://github.com/keras-team/keras/issues/9395\ndef dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n\ndef dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n\ndef dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n\n\n\n# Computing Precision \ndef precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\n    \n# Computing Sensitivity      \ndef sensitivity(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    return true_positives / (possible_positives + K.epsilon())\n\n\n# Computing Specificity\ndef specificity(y_true, y_pred):\n    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n    return true_negatives / (possible_negatives + K.epsilon())","metadata":{"_uuid":"b1ae51ea-e447-4236-90f0-1969f39d9240","_cell_guid":"3db9dc86-454a-4820-996d-34566609278e","collapsed":false,"id":"7ARHKXiEmHe1","execution":{"iopub.status.busy":"2022-10-06T21:22:01.932447Z","iopub.execute_input":"2022-10-06T21:22:01.932937Z","iopub.status.idle":"2022-10-06T21:22:01.952986Z","shell.execute_reply.started":"2022-10-06T21:22:01.932884Z","shell.execute_reply":"2022-10-06T21:22:01.951835Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_unet(inputs, ker_init, dropout):\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n    \n    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n    \n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n    \n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n    \n    drop5 = Dropout(dropout)(conv3)\n\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv3))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n    \n    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv9))\n    merge = concatenate([conv1,up], axis = 3)\n    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n    \n    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv)\n    \n    return Model(inputs = inputs, outputs = conv10)\n\ninput_layer = Input((IMG_SIZE, IMG_SIZE, 2))\n\nmodel = build_unet(input_layer, 'he_normal', 0.2)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )","metadata":{"_uuid":"c7485a00-7386-4541-95b7-c21aed180b51","_cell_guid":"23c528ed-6550-490f-b8d8-0ffb5e4bc5a4","collapsed":false,"id":"lNpSudj8mNRD","execution":{"iopub.status.busy":"2022-10-06T21:22:01.954888Z","iopub.execute_input":"2022-10-06T21:22:01.955236Z","iopub.status.idle":"2022-10-06T21:22:05.334748Z","shell.execute_reply.started":"2022-10-06T21:22:01.955180Z","shell.execute_reply":"2022-10-06T21:22:05.333769Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, \n           show_shapes = True,\n           show_dtype=False,\n           show_layer_names = True, \n           rankdir = 'TB', \n           expand_nested = False, \n           dpi = 70)","metadata":{"_uuid":"2f29827b-b88b-4ce5-8a0c-246d490fe551","_cell_guid":"4be75b1d-e6f2-4ac3-8f47-9e5ca1f6a33f","collapsed":false,"id":"J8WTz-37mX6U","outputId":"48ed770e-c7c9-405a-f23c-d685490bdb36","execution":{"iopub.status.busy":"2022-10-06T21:22:05.337390Z","iopub.execute_input":"2022-10-06T21:22:05.337988Z","iopub.status.idle":"2022-10-06T21:22:06.460382Z","shell.execute_reply.started":"2022-10-06T21:22:05.337923Z","shell.execute_reply":"2022-10-06T21:22:06.459323Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"_uuid":"62c238b1-57ec-4c64-aa2d-5b07e68a6a0f","_cell_guid":"16a33805-0e6e-48d6-b5b3-d731439c133d","collapsed":false,"id":"lwCIeRlymeCb","outputId":"6991938c-6bb8-4875-b390-b1a33d686b10","execution":{"iopub.status.busy":"2022-10-06T21:22:06.462220Z","iopub.execute_input":"2022-10-06T21:22:06.463008Z","iopub.status.idle":"2022-10-06T21:22:06.475766Z","shell.execute_reply.started":"2022-10-06T21:22:06.462949Z","shell.execute_reply":"2022-10-06T21:22:06.474607Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lists of directories with studies\ntrain_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]\n\n# file BraTS20_Training_355 has ill formatted name for for seg.nii file\n#train_and_val_directories.remove(TRAIN_DATASET_PATH+'BraTS20_Training_355')\n\n\ndef pathListIntoIds(dirList):\n    x = []\n    for i in range(0,len(dirList)):\n        x.append(dirList[i][dirList[i].rfind('/')+1:])\n    return x\n\ntrain_and_test_ids = pathListIntoIds(train_and_val_directories); \n\n    \ntrain_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2) \ntrain_ids, test_ids = train_test_split(train_test_ids,test_size=0.15)","metadata":{"_uuid":"49044cde-ddf1-4787-b958-e23cc2e9fb08","_cell_guid":"5a978f96-afe8-434f-9dec-41fe1788e992","collapsed":false,"id":"zo1p0EbJmh6h","execution":{"iopub.status.busy":"2022-10-06T21:22:06.477623Z","iopub.execute_input":"2022-10-06T21:22:06.478317Z","iopub.status.idle":"2022-10-06T21:22:06.491738Z","shell.execute_reply.started":"2022-10-06T21:22:06.478280Z","shell.execute_reply":"2022-10-06T21:22:06.490451Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_and_test_ids[0]","metadata":{"_uuid":"9162b982-f13a-4226-bc17-1761170222df","_cell_guid":"583954d1-2391-4954-931d-ce499f62cbcf","collapsed":false,"id":"44azT1RILr_R","outputId":"eb82307e-ecbe-4e82-fff3-761a6f9be15d","execution":{"iopub.status.busy":"2022-10-06T21:22:06.493368Z","iopub.execute_input":"2022-10-06T21:22:06.494138Z","iopub.status.idle":"2022-10-06T21:22:06.501106Z","shell.execute_reply.started":"2022-10-06T21:22:06.494034Z","shell.execute_reply":"2022-10-06T21:22:06.499983Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ids[0]","metadata":{"_uuid":"5376507f-5fae-4b4b-ad1f-f5b246e5614f","_cell_guid":"f7efb0c2-82c5-4ec6-bb65-c7d9aca34290","collapsed":false,"id":"Czbyhq3kMHQJ","outputId":"a8f6c3b5-925e-4bc4-ee2e-542a4a2f12f0","execution":{"iopub.status.busy":"2022-10-06T21:22:06.502827Z","iopub.execute_input":"2022-10-06T21:22:06.503587Z","iopub.status.idle":"2022-10-06T21:22:06.510960Z","shell.execute_reply.started":"2022-10-06T21:22:06.503552Z","shell.execute_reply":"2022-10-06T21:22:06.509810Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        Batch_ids = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(Batch_ids)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, Batch_ids):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))\n        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))\n\n        \n        # Generate data\n        for c, i in enumerate(Batch_ids):\n            case_path = os.path.join(TRAIN_DATASET_PATH, i)\n\n            data_path = os.path.join(case_path, f'{i}_flair.nii.gz');\n            flair = nib.load(data_path).get_fdata()    \n\n            data_path = os.path.join(case_path, f'{i}_t1ce.nii.gz');\n            ce = nib.load(data_path).get_fdata()\n            \n            data_path = os.path.join(case_path, f'{i}_seg.nii.gz');\n            seg = nib.load(data_path).get_fdata()\n        \n            for j in range(VOLUME_SLICES):\n                X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n                X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n\n                y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n                    \n        # Generate masks\n        y[y==4] = 3;\n        mask = tf.one_hot(y, 4);\n        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));\n        return X/np.max(X), Y\n        \ntraining_generator = DataGenerator(train_ids)\nvalid_generator = DataGenerator(val_ids)\ntest_generator = DataGenerator(test_ids)","metadata":{"_uuid":"e2cc7e09-c5dc-4f5c-a5fe-0b7984856060","_cell_guid":"0f785555-206e-4d22-89a4-0e94a5f5bb88","collapsed":false,"id":"Iq9ZCYrsmwdr","execution":{"iopub.status.busy":"2022-10-06T21:22:06.512615Z","iopub.execute_input":"2022-10-06T21:22:06.513287Z","iopub.status.idle":"2022-10-06T21:22:06.531876Z","shell.execute_reply.started":"2022-10-06T21:22:06.513253Z","shell.execute_reply":"2022-10-06T21:22:06.530839Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_ids))\nprint(len(val_ids))\nprint(len(test_ids))","metadata":{"_uuid":"a8a76783-9244-420b-8dd5-2bd445347a17","_cell_guid":"adcce3c4-528c-4e70-a394-862d9e09ee34","collapsed":false,"id":"t-hnTHVbm0tD","outputId":"147edb50-aa47-41c3-8a59-a78c9641733a","execution":{"iopub.status.busy":"2022-10-06T21:22:06.533334Z","iopub.execute_input":"2022-10-06T21:22:06.533917Z","iopub.status.idle":"2022-10-06T21:22:06.546482Z","shell.execute_reply.started":"2022-10-06T21:22:06.533882Z","shell.execute_reply":"2022-10-06T21:22:06.545337Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show number of data for each dir \ndef showDataLayout():\n    plt.bar([\"Train\",\"Valid\",\"Test\"],\n    [len(train_ids), len(val_ids), len(test_ids)], align='center',color=[ 'green','red', 'blue'])\n    plt.legend()\n\n    plt.ylabel('Number of images')\n    plt.title('Data distribution')\n    plt.savefig('data2018.png')\n    plt.show()\n    \nshowDataLayout()","metadata":{"_uuid":"15df43fd-e500-4067-88de-fd951207c754","_cell_guid":"598b89b9-37be-4e8e-8232-0bf227a6a179","collapsed":false,"id":"ldka-h8Em6NT","outputId":"e27800c5-1eb2-4e8e-d5e8-e3be3fad5c1a","execution":{"iopub.status.busy":"2022-10-06T21:22:06.548203Z","iopub.execute_input":"2022-10-06T21:22:06.548667Z","iopub.status.idle":"2022-10-06T21:22:06.780588Z","shell.execute_reply.started":"2022-10-06T21:22:06.548581Z","shell.execute_reply":"2022-10-06T21:22:06.779616Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping\n\nfilepath=\"3D-UNet-2018-weights-improvement-{epoch:02d}-{val_accuracy:.3f}.hdf5\" \n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n\ncsv_logger = CSVLogger('training_2021_2D_UNet.log')\n\nhistory =  model.fit(training_generator,\n                    epochs=30, \n                    steps_per_epoch=len(train_ids),\n                    callbacks= [checkpoint, csv_logger, early_stop],\n                    validation_data = valid_generator\n                    )","metadata":{"_uuid":"0dacfd96-59c9-4cb2-80c5-f4751f64a532","_cell_guid":"62a6793b-b13b-4381-ad0f-cbb122d48512","collapsed":false,"id":"Twarmca4nEWL","outputId":"ee11fd25-140e-4d85-c903-d7ff221265d9","execution":{"iopub.status.busy":"2022-10-06T21:22:06.782215Z","iopub.execute_input":"2022-10-06T21:22:06.782823Z","iopub.status.idle":"2022-10-06T23:03:17.052796Z","shell.execute_reply.started":"2022-10-06T21:22:06.782785Z","shell.execute_reply":"2022-10-06T23:03:17.050486Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"model_2021_2D_UNet.h5\")","metadata":{"_uuid":"981cd365-cd9e-4c6e-85de-e6ac0a5febf4","_cell_guid":"2ea60721-645e-42b9-b332-f1ffc8526902","collapsed":false,"id":"-abCCMlXfqR2","execution":{"iopub.status.busy":"2022-10-06T23:03:17.056987Z","iopub.execute_input":"2022-10-06T23:03:17.058422Z","iopub.status.idle":"2022-10-06T23:03:17.182441Z","shell.execute_reply.started":"2022-10-06T23:03:17.058391Z","shell.execute_reply":"2022-10-06T23:03:17.181453Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"############ load trained model ################\nmodel = tf.keras.models.load_model('model_2021_2D_UNet.h5', \n                                   custom_objects={ 'accuracy' : tf.keras.metrics.MeanIoU(num_classes=4),\n                                                   \"dice_coef\": dice_coef,\n                                                   \"precision\": precision,\n                                                   \"sensitivity\":sensitivity,\n                                                   \"specificity\":specificity,\n                                                   \"dice_coef_necrotic\": dice_coef_necrotic,\n                                                   \"dice_coef_edema\": dice_coef_edema,\n                                                   \"dice_coef_enhancing\": dice_coef_enhancing\n                                                  }, compile=False)\n\nhistory = pd.read_csv('training_2021_2D_UNet.log', sep=',', engine='python')\n\nhist=history\n\n############### ########## ####### #######\n\n# hist=history.history\n\nacc=hist['accuracy']\nval_acc=hist['val_accuracy']\n\nepoch=range(len(acc))\n\nloss=hist['loss']\nval_loss=hist['val_loss']\n\ntrain_dice=hist['dice_coef']\nval_dice=hist['val_dice_coef']\n\nf,ax=plt.subplots(1,4,figsize=(16,8))\n\nax[0].plot(epoch,acc,'b',label='Training Accuracy')\nax[0].plot(epoch,val_acc,'r',label='Validation Accuracy')\nax[0].legend()\n\nax[1].plot(epoch,loss,'b',label='Training Loss')\nax[1].plot(epoch,val_loss,'r',label='Validation Loss')\nax[1].legend()\n\nax[2].plot(epoch,train_dice,'b',label='Training dice coef')\nax[2].plot(epoch,val_dice,'r',label='Validation dice coef')\nax[2].legend()\n\nax[3].plot(epoch,hist['mean_io_u'],'b',label='Training mean IOU')\nax[3].plot(epoch,hist['val_mean_io_u'],'r',label='Validation mean IOU')\nax[3].legend()\nplt.savefig('training_result_2018.png')\nplt.show()","metadata":{"_uuid":"03dd594e-2cd6-42e9-8a92-a3d3861fef3f","_cell_guid":"1f79a1b4-3982-4512-a84d-adf4a4ecf4c6","collapsed":false,"id":"BA5Wh3ETfwaS","outputId":"f92d723c-4262-412b-fe8f-cdbe732f5bd8","execution":{"iopub.status.busy":"2022-10-06T23:03:17.184020Z","iopub.execute_input":"2022-10-06T23:03:17.184354Z","iopub.status.idle":"2022-10-06T23:03:18.269956Z","shell.execute_reply.started":"2022-10-06T23:03:17.184318Z","shell.execute_reply":"2022-10-06T23:03:18.268858Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mri type must one of 1) flair 2) t1 3) t1ce 4) t2 ------- or even 5) seg\n# returns volume of specified study at `path`\ndef imageLoader(path):\n    image = nib.load(path).get_fdata()\n    X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))\n    for j in range(VOLUME_SLICES):\n        X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(image[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n        X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));\n\n        y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];\n    return np.array(image)\n\n\n# load nifti file at `path`\n# and load each slice with mask from volume\n# choose the mri type & resize to `IMG_SIZE`\ndef loadDataFromDir(path, list_of_files, mriType, n_images):\n    scans = []\n    masks = []\n    for i in list_of_files[:n_images]:\n        fullPath = glob.glob( i + '/*'+ mriType +'*')[0]\n        currentScanVolume = imageLoader(fullPath)\n        currentMaskVolume = imageLoader( glob.glob( i + '/*seg*')[0] ) \n        # for each slice in 3D volume, find also it's mask\n        for j in range(0, currentScanVolume.shape[2]):\n            scan_img = cv2.resize(currentScanVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n            mask_img = cv2.resize(currentMaskVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')\n            scans.append(scan_img[..., np.newaxis])\n            masks.append(mask_img[..., np.newaxis])\n    return np.array(scans, dtype='float32'), np.array(masks, dtype='float32')\n        \n#brains_list_test, masks_list_test = loadDataFromDir(VALIDATION_DATASET_PATH, test_directories, \"flair\", 5)","metadata":{"_uuid":"6ca13b7a-bf50-4526-a0b8-284db2d45fee","_cell_guid":"8d509af6-0b92-4697-b03a-16ffe709d3dd","collapsed":false,"id":"WHzsHqCbf5l0","execution":{"iopub.status.busy":"2022-10-06T23:03:18.271306Z","iopub.execute_input":"2022-10-06T23:03:18.271958Z","iopub.status.idle":"2022-10-06T23:03:18.286039Z","shell.execute_reply.started":"2022-10-06T23:03:18.271920Z","shell.execute_reply":"2022-10-06T23:03:18.285037Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predictByPath(case_path,case):\n    files = next(os.walk(case_path))[2]\n    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))\n  #  y = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE))\n\n   # /content/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_10_1/Brats18_2013_10_1_flair.nii\n\n    #vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_flair.nii');\n    vol_path = case_path + case + '_flair.nii.gz';\n    flair=nib.load(vol_path).get_fdata()\n    \n    #vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii');\n    vol_path = case_path + case + '_t1ce.nii.gz';\n    ce=nib.load(vol_path).get_fdata() \n    \n #   vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_seg.nii');\n #   seg=nib.load(vol_path).get_fdata()  \n\n    \n    for j in range(VOLUME_SLICES):\n        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n        X[j,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n #       y[j,:,:] = cv2.resize(seg[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))\n        \n  #  model.evaluate(x=X,y=y[:,:,:,0], callbacks= callbacks)\n    return model.predict(X/np.max(X), verbose=1)\n\ndef showPredictsById(case, start_slice = 60):\n    path = TRAIN_DATASET_PATH + case + '/'\n\n    # TRAIN_DATASET_PATH + test_ids[0] + \"/\" + test_ids[0] + '_flair.nii'\n\n    gt = nib.load(path + case +'_seg.nii.gz').get_fdata()\n    origImage = nib.load(path + case +'_flair.nii.gz').get_fdata()\n    p = predictByPath(path,case)\n\n    core = p[:,:,:,1]\n    edema= p[:,:,:,2]\n    enhancing = p[:,:,:,3]\n\n    plt.figure(figsize=(18, 50))\n    f, axarr = plt.subplots(1,6, figsize = (18, 50)) \n\n    for i in range(6): # for each image, add brain background\n        axarr[i].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\", interpolation='none')\n    \n    axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap=\"gray\")\n    axarr[0].title.set_text('Original image flair')\n    curr_gt=cv2.resize(gt[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)\n    axarr[1].imshow(curr_gt, cmap=\"Reds\", interpolation='none', alpha=0.3) # ,alpha=0.3,cmap='Reds'\n    axarr[1].title.set_text('Ground truth')\n    axarr[2].imshow(p[start_slice,:,:,1:4], cmap=\"Reds\", interpolation='none', alpha=0.3)\n    axarr[2].title.set_text('all classes')\n    axarr[3].imshow(edema[start_slice,:,:], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[3].title.set_text(f'{SEGMENT_CLASSES[1]} predicted')\n    axarr[4].imshow(core[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[4].title.set_text(f'{SEGMENT_CLASSES[2]} predicted')\n    axarr[5].imshow(enhancing[start_slice,:,], cmap=\"OrRd\", interpolation='none', alpha=0.3)\n    axarr[5].title.set_text(f'{SEGMENT_CLASSES[3]} predicted')\n    plt.savefig('Test_01.png')\n    plt.show()\n    \n    \nshowPredictsById(case=test_ids[0])\nshowPredictsById(case=test_ids[1])\nshowPredictsById(case=test_ids[2])\nshowPredictsById(case=test_ids[3])\nshowPredictsById(case=test_ids[4])\nshowPredictsById(case=test_ids[5])\nshowPredictsById(case=test_ids[6])","metadata":{"_uuid":"d41f697b-8650-45ab-b1b8-451f924e23c3","_cell_guid":"6db3de08-d284-48b7-a99e-20b7afc44dac","collapsed":false,"id":"cL0s-oAuf_EV","outputId":"fbf370e2-4981-4720-8b04-19f7056939cf","execution":{"iopub.status.busy":"2022-10-06T23:03:18.287706Z","iopub.execute_input":"2022-10-06T23:03:18.288114Z","iopub.status.idle":"2022-10-06T23:03:31.585623Z","shell.execute_reply.started":"2022-10-06T23:03:18.288079Z","shell.execute_reply":"2022-10-06T23:03:31.584480Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# /content/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_10_1/Brats18_2013_10_1_flair.nii","metadata":{"_uuid":"e95bcbae-eba8-4aeb-b555-adc3b9d473c2","_cell_guid":"83dc9a09-f015-468e-bccb-943d3fc3c9d9","collapsed":false,"id":"lXvnZpVoNr0z","execution":{"iopub.status.busy":"2022-10-06T23:03:31.591686Z","iopub.execute_input":"2022-10-06T23:03:31.592083Z","iopub.status.idle":"2022-10-06T23:03:31.597292Z","shell.execute_reply.started":"2022-10-06T23:03:31.592045Z","shell.execute_reply":"2022-10-06T23:03:31.596068Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ids[0]","metadata":{"_uuid":"b8f985fe-977c-4c17-a0ca-e30ced44f7d3","_cell_guid":"ba42d203-bf20-45ae-a2e6-6c64c78d6908","collapsed":false,"id":"ZfiGgYBdNOEh","outputId":"913c8a7b-fe66-4ff7-d0e0-83d1c1141046","execution":{"iopub.status.busy":"2022-10-06T23:03:31.599151Z","iopub.execute_input":"2022-10-06T23:03:31.599645Z","iopub.status.idle":"2022-10-06T23:03:31.610032Z","shell.execute_reply.started":"2022-10-06T23:03:31.599607Z","shell.execute_reply":"2022-10-06T23:03:31.609047Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DATASET_PATH + test_ids[0] + \"/\" + test_ids[0] + '_flair.nii'","metadata":{"_uuid":"c9f2d611-43f9-4562-b914-80124d66e7ac","_cell_guid":"9df69765-637d-48cf-90b5-12a240b92426","collapsed":false,"id":"Q8RM4ws4NQAL","outputId":"3a07abb0-86e8-41f2-c434-ec6878f83e89","execution":{"iopub.status.busy":"2022-10-06T23:03:31.611262Z","iopub.execute_input":"2022-10-06T23:03:31.612353Z","iopub.status.idle":"2022-10-06T23:03:31.619831Z","shell.execute_reply.started":"2022-10-06T23:03:31.612308Z","shell.execute_reply":"2022-10-06T23:03:31.618756Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"case = test_ids[4]\n# path = f\"../input/brats2018-dataset/MICCAI_BraTS_2018_Data_Training/Brats18_{case}\"\npath = TRAIN_DATASET_PATH + test_ids[4] + \"/\" \ngt = nib.load(path + test_ids[4] +'_seg.nii.gz').get_fdata()\np = predictByPath(path,case)\n\n\ncore = p[:,:,:,1]\nedema= p[:,:,:,2]\nenhancing = p[:,:,:,3]\n\n\ni=40 # slice at\neval_class =3 #     0 : 'NOT tumor',  1 : 'ENHANCING',    2 : 'CORE',    3 : 'WHOLE'\n\n\n\ngt[gt != eval_class] = 1 # use only one class for per class evaluation \n\nresized_gt = cv2.resize(gt[:,:,i+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))\n\nplt.figure()\nf, axarr = plt.subplots(1,2) \naxarr[0].imshow(resized_gt, cmap=\"gray\")\naxarr[0].title.set_text('ground truth')\naxarr[1].imshow(p[i,:,:,eval_class], cmap=\"gray\")\naxarr[1].title.set_text(f'predicted class: {SEGMENT_CLASSES[eval_class]}')\nplt.show()","metadata":{"_uuid":"1266fb1c-0524-40a9-8264-c4d15930a6eb","_cell_guid":"7af98f9a-d15e-4480-a9ef-7341f69275dc","collapsed":false,"id":"2xxaZ1s3gDsP","outputId":"21e0a8f1-2ba5-4145-ff81-ac9eb05d22d3","execution":{"iopub.status.busy":"2022-10-06T23:03:31.621135Z","iopub.execute_input":"2022-10-06T23:03:31.622041Z","iopub.status.idle":"2022-10-06T23:03:32.445534Z","shell.execute_reply.started":"2022-10-06T23:03:31.622006Z","shell.execute_reply":"2022-10-06T23:03:32.444539Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_logger = CSVLogger('./evaluation_50.log')\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing] )\n# Evaluate the model on the test data using `evaluate`\nprint(\"Evaluate on test data\")\nresults = model.evaluate(test_generator, batch_size=100, callbacks= [csv_logger])\nprint(\"test loss, test acc:\", results)","metadata":{"_uuid":"493ae27f-4251-4160-9121-3e9b8c950b8d","_cell_guid":"6c6f2c41-5856-4e12-bea3-78d2189afafa","collapsed":false,"id":"PZYaUl1_gGH_","outputId":"dba033cb-5213-4e34-d5c2-1245c6d5f746","execution":{"iopub.status.busy":"2022-10-06T23:03:32.447014Z","iopub.execute_input":"2022-10-06T23:03:32.447594Z","iopub.status.idle":"2022-10-06T23:04:56.153180Z","shell.execute_reply.started":"2022-10-06T23:03:32.447557Z","shell.execute_reply":"2022-10-06T23:04:56.152105Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"9ee77eb8-407b-4023-904e-3827b9c7467f","_cell_guid":"e9095ad9-002c-41b5-89be-89d049c02678","collapsed":false,"id":"6lHekC2UgIdH","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}